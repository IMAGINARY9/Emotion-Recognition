# Configuration for BiLSTM-based emotion recognition model

model:
  type: "bilstm"
  vocab_size: 15000
  embedding_dim: 300
  hidden_dim: 384  # Increased hidden size for more capacity
  num_layers: 2   # Reduce LSTM layers for easier optimization
  num_classes: 6
  dropout_rate: 0.2  # Slightly higher dropout
  max_length: 128
  bidirectional: true
  attention: true  # Re-enable attention
  
  # Pre-trained embeddings
  pretrained_embeddings:
    use: true
    path: null  # Will use GloVe 300d if available
    freeze: false
  loss_type: cross_entropy  # Use standard cross-entropy loss
  gamma: 2.0
  label_smoothing: 0.0  # Turn off label smoothing
  freeze: false     # Ensure embeddings are trainable
    
training:
  batch_size: 128  # Larger batch size for more stable gradients
  learning_rate: 0.002  # Slightly higher learning rate
  optimizer: adamw      # Use AdamW optimizer
  num_epochs: 30  # More epochs with lower learning rate
  warmup_steps: 500  # More warmup steps
  weight_decay: 0.01     # Add some weight decay
  gradient_clip_norm: 1.0  # Lower gradient clipping for stability
    # Learning rate scheduler
  scheduler:
    type: "one_cycle"  # Use one-cycle scheduler if supported
    step_size: 10
    gamma: 0.5
    min_lr: 1e-6
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 15  # Allow more epochs before stopping
    min_delta: 0.001
    metric: "val_f1"
    mode: "max"

data:
  max_length: 128
  text_column: "text"
  label_column: "label"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  
  # Data loading
  batch_sizes:
    train: 32  # Match training batch size
    validation: 64
    test: 128
  
  shuffle:
    train: true
    validation: false
    test: false
  
  num_workers: 0

preprocessing:
  # Text preprocessing options (more aggressive for LSTM)
  lowercase: true
  remove_urls: true
  remove_mentions: true
  remove_hashtags: false
  remove_extra_whitespace: true
  remove_stopwords: false
  expand_contractions: true
  
  # Emoji handling
  emoji_handling: "convert"  # Remove emojis for traditional model
  
  # Special tokens
  add_special_tokens: false
  
  # Vocabulary building
  min_freq: 1
  max_vocab_size: 15000

evaluation:
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision_macro"
    - "recall_macro"
    - "roc_auc"
  
  # Visualization options
  plot_confusion_matrix: true
  plot_training_history: true
  plot_embeddings: true
  save_predictions: true

paths:
  data_dir: "data"
  model_dir: "models"
  output_dir: "outputs"
  log_dir: "logs"
  cache_dir: "cache"
  
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
device:
  # Auto-detect device or specify manually
  auto_detect: true
  force_cpu: false
  
# Emotion labels (must match dataset)
emotions:
  - "sadness"
  - "joy"
  - "love"
  - "anger"
  - "fear"
  - "surprise"

advanced:
  data_augmentation:
    enabled: true
    techniques:
      - "synonym_replacement"
      - "random_insertion"
      - "random_swap"
    augmentation_ratio: 0.2
  class_weighting:
    enabled: true
    strategy: "balanced"
  mixed_precision:
    enabled: false
  gradient_accumulation:
    enabled: true
    steps: 2
