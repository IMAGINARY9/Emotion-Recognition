# Configuration for BiLSTM-based emotion recognition model

model:
  type: "bilstm"
  vocab_size: 12678
  embedding_dim: 300
  hidden_dim: 512  # Increased hidden size for more capacity
  num_layers: 3    # More layers for deeper learning
  num_classes: 6
  dropout_rate: 0.2  # Lower dropout for BiLSTM
  max_length: 256   # Allow longer sequences
  bidirectional: true
  attention: true
  
  # Pre-trained embeddings
  pretrained_embeddings:
    use: true
    path: null  # Will use GloVe 300d if available
    freeze: false
    
  # Loss function
  loss_type: focal  # Options: 'cross_entropy', 'focal'
  gamma: 2.0        # Focal loss focusing parameter
  label_smoothing: 0.0  # Label smoothing for loss
  freeze: false     # Ensure embeddings are trainable
    
training:
  batch_size: 64
  learning_rate: 0.001  # Higher learning rate for BiLSTM
  optimizer: adamw      # Use AdamW optimizer
  num_epochs: 30
  warmup_steps: 0
  weight_decay: 0.0     # No weight decay for BiLSTM
  gradient_clip_norm: 5.0
  
  # Learning rate scheduler
  scheduler:
    type: "step"
    step_size: 5
    gamma: 0.5
  
  # Early stopping
  early_stopping:
    enabled: true
    patience: 7  # More patience for early stopping
    min_delta: 0.001
    metric: "val_f1"
    mode: "max"

data:
  max_length: 128
  text_column: "text"
  label_column: "label"
  train_split: 0.8
  val_split: 0.1
  test_split: 0.1
  
  # Data loading
  batch_sizes:
    train: 64
    validation: 128
    test: 128
  
  shuffle:
    train: true
    validation: false
    test: false
  
  num_workers: 0

preprocessing:
  # Text preprocessing options (more aggressive for LSTM)
  lowercase: true
  remove_urls: true
  remove_mentions: true
  remove_hashtags: true
  remove_extra_whitespace: true
  remove_stopwords: true
  expand_contractions: true
  
  # Emoji handling
  emoji_handling: "remove"  # Remove emojis for traditional model
  
  # Special tokens
  add_special_tokens: false
  
  # Vocabulary building
  min_freq: 2
  max_vocab_size: 10000

evaluation:
  metrics:
    - "accuracy"
    - "f1_macro"
    - "f1_weighted"
    - "precision_macro"
    - "recall_macro"
    - "roc_auc"
  
  # Visualization options
  plot_confusion_matrix: true
  plot_training_history: true
  plot_embeddings: true
  save_predictions: true

paths:
  data_dir: "data"
  model_dir: "models"
  output_dir: "outputs"
  log_dir: "logs"
  cache_dir: "cache"
  
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
device:
  # Auto-detect device or specify manually
  auto_detect: true
  force_cpu: false
  
# Emotion labels (must match dataset)
emotions:
  - "sadness"
  - "joy"
  - "love"
  - "anger"
  - "fear"
  - "surprise"
